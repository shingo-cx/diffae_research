{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "814123ef-9ea3-4081-88e4-3db35e277e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "546d826b-7b18-4734-80b2-63c653a57aef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: azuki_default.png\n",
      " 1: ceo_default.png\n",
      " 2: check1.png\n",
      " 3: check2.png\n",
      " 4: danda_default.png\n",
      " 5: detective.png\n",
      " 6: detective_02.png\n",
      " 7: idPhoto.png\n",
      " 8: mio_happy.png\n",
      " 9: mio_shock.png\n",
      "10: mio_silence.png\n",
      "11: mio_u.png\n",
      "12: nanko_default.png\n",
      "13: ookawa_angry.png\n",
      "14: ookawa_angry2.png\n",
      "15: ookawa_default.png\n",
      "16: ookawa_high.png\n",
      "17: ookawa_regret.png\n",
      "18: ookawa_smile.png\n",
      "19: ookawa_surprised.png\n",
      "20: pharmacist.png\n",
      "21: saki.png\n",
      "22: saki_glasses.png\n",
      "23: sandy.png\n",
      "24: takebe_default.png\n",
      "25: test01.png\n",
      "26: test01_02.png\n",
      "27: test01_03.png\n",
      "28: test01_04.png\n",
      "29: test02.png\n",
      "30: woman_default.png\n",
      "31: yotaka_angry.png\n",
      "32: yotaka_angry2.png\n",
      "33: yotaka_bald.png\n",
      "34: yotaka_bushy.png\n",
      "35: yotaka_default.png\n",
      "36: yotaka_gj.png\n",
      "37: yotaka_smile.png\n",
      "38: yotaka_smile2.png\n",
      "\n",
      "total: 39\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'imgs_align'\n",
    "num_files = 0\n",
    "for i,file in enumerate(os.listdir(img_dir)):\n",
    "    print(f'{i:2}: {file}')\n",
    "    num_files += 1\n",
    "print(f'\\ntotal: {num_files}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "af1fe7cc-6461-4877-84e9-85dbc07b61bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c46fbd3a-f301-4d22-a648-b5be829cabde",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_face1 = np.zeros((256,256,3)).astype(np.uint64)\n",
    "avg_face2 = torch.zeros(3,256,256)\n",
    "for i,file in enumerate(os.listdir(img_dir)):\n",
    "    img1 = cv2.imread(f'{img_dir}/{file}')\n",
    "    avg_face1 += img1\n",
    "    img2 = Image.open(f'{img_dir}/{file}')\n",
    "    img2 = transform(img2)\n",
    "    avg_face2 += img2\n",
    "\n",
    "avg_face1 = avg_face1 // num_files\n",
    "avg_face1 = avg_face1.astype(np.uint8)\n",
    "avg_face2 = avg_face2 / num_files\n",
    "avg_face2 = (avg_face2+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dfbfd722-ccc1-4672-94c9-2718d0998406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a, b):\n",
    "    a = a.view(-1)\n",
    "    b = b.view(-1)\n",
    "    a = F.normalize(a, dim=0)\n",
    "    b = F.normalize(b, dim=0)\n",
    "    return (a * b).sum()\n",
    "\n",
    "def interpolate(img1, img2):\n",
    "    img_shape = img1.shape\n",
    "    theta = torch.arccos(cos(img1, img2))\n",
    "    img_avg = (torch.sin(0.5 * theta) * img1.flatten(0, 2) + torch.sin(0.5 * theta) * img2.flatten(0, 2)) / torch.sin(theta)\n",
    "    img_avg = img_avg.view(*img_shape)\n",
    "    return img_avg\n",
    "\n",
    "def make_average_face(imgs):\n",
    "    if len(imgs) < 2:\n",
    "        return imgs[0]\n",
    "    random.shuffle(imgs)\n",
    "    imgs2 = []\n",
    "    for i in range(0, len(imgs)-1, 2):\n",
    "        img_avg = interpolate(imgs[i], imgs[i+1])\n",
    "        imgs2.append(img_avg)\n",
    "    if len(imgs) > 2 and len(imgs)//2 != 0:\n",
    "        imgs2.append(imgs[-1])\n",
    "    return make_average_face(imgs2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "bf3eb341-57cd-4cf6-8f75-c8614f9a997f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for file in os.listdir(img_dir):\n",
    "    img = Image.open(f'{img_dir}/{file}')\n",
    "    img = transform(img)\n",
    "    imgs.append(img)\n",
    "\n",
    "avg_face3 = make_average_face(imgs)\n",
    "avg_face3 = (avg_face3+1)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d22baa2f-7c73-49df-8f3b-cdf54a846afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = 'imgs_test/imgs_avg/'\n",
    "if not os.path.exists(dst_dir): os.makedirs(dst_dir)\n",
    "cv2.imwrite(f'{dst_dir}avg_face1.png', avg_face1)\n",
    "save_image(avg_face2, f'{dst_dir}avg_face2.png', format='PNG')\n",
    "save_image(avg_face3, f'{dst_dir}avg_face3.png', format='PNG')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
