{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7388c98c-7f8e-4f01-9a88-2f4c1eb46d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4d4f1a7-0d20-43c1-9222-33f734b4cb87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from templates import *\n",
    "from templates_cls import *\n",
    "from experiment_classifier import ClsModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85ccbbca-aa7c-4dcf-8dbd-58487700862e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model params: 160.69 M\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "conf = ffhq256_autoenc()\n",
    "# print(conf.name)\n",
    "model = LitModel(conf)\n",
    "state = torch.load(f'checkpoints/{conf.name}/last.ckpt', map_location='cpu')\n",
    "model.load_state_dict(state['state_dict'], strict=False)\n",
    "model.ema_model.eval()\n",
    "model.ema_model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "734d6900-ac01-4891-832c-947947c396c8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrain ... 130M\n",
      "step: 1563562\n",
      "loading latent stats ...\n",
      "latent step: 9375\n"
     ]
    }
   ],
   "source": [
    "cls_conf = ffhq256_autoenc_cls()\n",
    "cls_model = ClsModel(cls_conf)\n",
    "state = torch.load(f'checkpoints/{cls_conf.name}/last.ckpt',\n",
    "                    map_location='cpu')\n",
    "print('latent step:', state['global_step'])\n",
    "cls_model.load_state_dict(state['state_dict'], strict=False)\n",
    "cls_model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9fde66-f53f-40aa-aea8-2f9f9d6ecb4b",
   "metadata": {},
   "source": [
    "## 選択"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "675eac93-9e9f-48f1-9500-89ee4c02050b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0: frame_001.png\n"
     ]
    }
   ],
   "source": [
    "img_pose_dir = 'videos_test/video1/pose/'\n",
    "img_eye_dir = 'videos_test/video1/syn/eye/'\n",
    "img_mouth_dir = 'videos_test/video1/syn/mouth/'\n",
    "img_to_dir = 'videos_test/img/'\n",
    "for i,file in enumerate(os.listdir(img_to_dir)):\n",
    "    print(f'{i:2}: {file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7df865ae-155c-43db-a760-018121658a9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_pose = ImageDataset(img_pose_dir, image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False, sort_names=True)\n",
    "data_eye = ImageDataset(img_eye_dir, image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False, sort_names=True)\n",
    "data_mouth = ImageDataset(img_mouth_dir, image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False, sort_names=True)\n",
    "data_to = ImageDataset(img_to_dir, image_size=conf.img_size, exts=['jpg', 'JPG', 'png'], do_augment=False, sort_names=True)\n",
    "batch_pose = torch.tensor([])\n",
    "batch_eye = torch.tensor([])\n",
    "batch_mouth = torch.tensor([])\n",
    "batch_to = torch.tensor([])\n",
    "names_batch_to = []\n",
    "for i in range(len(data_pose)):\n",
    "    batch_pose = torch.cat([batch_pose, data_pose[i]['img'][None]], axis=0)\n",
    "    batch_eye = torch.cat([batch_eye, data_eye[i]['img'][None]], axis=0)\n",
    "    batch_mouth = torch.cat([batch_mouth, data_mouth[i]['img'][None]], axis=0)\n",
    "\n",
    "for i in range(len(data_to)):\n",
    "    batch_to = torch.cat([batch_to, data_to[i]['img'][None]], axis=0)\n",
    "    names_batch_to.append(os.path.splitext(str(data_to.paths[i]))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8787499f-503f-403c-9457-c4e9521540be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cond_pose = torch.tensor([], device=device)\n",
    "cond_eye = torch.tensor([], device=device)\n",
    "cond_mouth = torch.tensor([], device=device)\n",
    "cond_to = torch.tensor([], device=device)\n",
    "cond_to_norm = torch.tensor([], device=device)\n",
    "xT_to = torch.tensor([], device=device)\n",
    "\n",
    "for i in range(len(batch_pose)):\n",
    "    cond_pose = torch.cat([cond_pose, model.encode(batch_pose[i][None].to(device))], dim=0)\n",
    "    cond_eye = torch.cat([cond_eye, model.encode(batch_eye[i][None].to(device))], dim=0)\n",
    "    cond_mouth = torch.cat([cond_mouth, model.encode(batch_mouth[i][None].to(device))], dim=0)\n",
    "\n",
    "for i in range(len(batch_to)):\n",
    "    cond_to = torch.cat([cond_to, model.encode(batch_to[i][None].to(device))], dim=0)\n",
    "    cond_to_norm = torch.cat([cond_to_norm, cls_model.normalize(cond_to[i])], dim=0)\n",
    "    xT_to = torch.cat([xT_to, model.encode_stochastic(batch_to[i][None].to(device), cond_to[i][None], T=250)], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18322bce-303a-44f6-bacd-52cb811c8590",
   "metadata": {},
   "source": [
    "## pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dd21fea-4e53-48f4-8c67-1176e9fe4107",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_change_pose = torch.tensor([], device=device)\n",
    "for i in range(len(batch_pose)):\n",
    "    cond_change = cls_model.normalize(cond_pose[i][None]) - cls_model.normalize(cond_pose[0][None])\n",
    "    cond_change_pose = torch.cat([cond_change_pose, cond_change], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d4968d4-3c79-422a-8093-2b7207697a22",
   "metadata": {},
   "source": [
    "## eye"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5589c915-a2ee-45e0-b66c-77857e9cfa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_change_eye = torch.tensor([], device=device)\n",
    "for i in range(len(batch_eye)):\n",
    "    cond_change = cls_model.normalize(cond_eye[i][None]) - cls_model.normalize(cond_eye[0][None])\n",
    "    cond_change_eye = torch.cat([cond_change_eye, cond_change], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38ba5a8-f027-4720-bdf4-41062e6cd506",
   "metadata": {},
   "source": [
    "## mouth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a106444-ea79-460b-990a-1248245dec23",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_change_mouth = torch.tensor([], device=device)\n",
    "for i in range(len(batch_mouth)):\n",
    "    cond_change = cls_model.normalize(cond_mouth[i][None]) - cls_model.normalize(cond_mouth[0][None])\n",
    "    cond_change_mouth = torch.cat([cond_change_mouth, cond_change], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc8966e-4292-444d-a0c7-23fe81609f32",
   "metadata": {},
   "source": [
    "## 推論"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6896acba-d29e-47cc-84c8-205102faf211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 12min 7s\n",
      "Wall time: 16min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds = torch.tensor([], device=device)\n",
    "for i in range(len(batch_to)):\n",
    "    preds_tmp = torch.tensor([], device=device)\n",
    "    for j in range(len(batch_pose)):\n",
    "        cond2 = cond_to_norm[i] + cond_change_pose[j]\n",
    "        cond2 = cls_model.denormalize(cond2)\n",
    "        pred = model.render(xT_to[i][None], cond2, T=20)\n",
    "        preds_tmp = torch.cat([preds_tmp, pred], dim=0)\n",
    "    preds = torch.cat([preds, preds_tmp[None]], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c57b8b5f-f0d7-4ee2-b1ed-5adb1b2ea6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "preds_pil = []\n",
    "for pred in preds:\n",
    "    pred_pil = []\n",
    "    for p in pred:\n",
    "        p_np = np.array((p*255).permute(1,2,0).cpu()).astype(np.uint8)\n",
    "        pred_pil.append(Image.fromarray(p_np))\n",
    "    preds_pil.append(pred_pil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec4594e-7457-4bba-9e5d-40e47b34fc19",
   "metadata": {
    "tags": []
   },
   "source": [
    "## gifの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a5f1d29-62bd-4c9d-b324-d116bb8c7262",
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_dir = f\"videos_test/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a072a2dc-c76f-44fc-8f9a-9e54658add48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i,pred_pil in enumerate(preds_pil):\n",
    "    dst_dir_gif = f\"{dst_dir}/gif/\"\n",
    "    if not os.path.exists(dst_dir_gif): os.makedirs(dst_dir_gif)\n",
    "    file_name = f\"result_pose.gif\"\n",
    "    dst_path = dst_dir_gif + file_name\n",
    "\n",
    "    pred_pil[0].save(\n",
    "        dst_path,\n",
    "        format=\"gif\",\n",
    "        save_all=True,\n",
    "        append_images=pred_pil,\n",
    "        duration=33,\n",
    "        loop=0,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c40259-8edc-4bef-ab62-6eee45d797fa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 静止画像（フレーム）の保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "219f96bc-3bd5-4772-ae3b-178a59d5d870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "\n",
    "select_ind = set(range(len(batch_pose))\n",
    "for i,pred in enumerate(preds):\n",
    "    dst_dir_frames = f\"{dst_dir}/frames/\"\n",
    "    if not os.path.exists(dst_dir_frames): os.makedirs(dst_dir_frames)\n",
    "    for j,p in enumerate(pred):\n",
    "        if j in select_ind:\n",
    "            file_name = f\"{dst_dir_frames}{j+1:03}.png\"\n",
    "            save_image(p, file_name, format='PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7130797e-6b95-4775-b4fe-a9c2a2400262",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
